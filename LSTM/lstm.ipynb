{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289db6fc-8743-4bb8-8e9f-b4f03e641961",
   "metadata": {},
   "source": [
    "# LSTM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1afa7b7-f1f4-4c76-84fa-045050f04461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04f235d-47eb-42c2-b211-86a437172469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change this to the path of the data directory\n",
    "path = \"./clin-summ/data\"\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0747e3ad-6376-4a53-892b-13bec9cf4999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2735,) (2735,) (343,) (343,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "assert os.path.exists(path), 'Dataset not found ({})'.format(data_path)\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_json(os.path.join(path, \"train.jsonl\"), lines=True)\n",
    "    train_x, train_y = df[\"inputs\"].to_numpy(), df[\"target\"].to_numpy()\n",
    "    df = pd.read_json(os.path.join(path, \"test.jsonl\"), lines=True)\n",
    "    test_x, test_y = df[\"inputs\"].to_numpy(), df[\"target\"].to_numpy()\n",
    "    \n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "opi = load_data(os.path.join(path, 'opi'))\n",
    "d2n = load_data(os.path.join(path, 'd2n'))\n",
    "chq = load_data(os.path.join(path, 'chq'))\n",
    "\n",
    "all_xy = np.concatenate((opi, d2n, chq))\n",
    "train_x = all_xy[0]\n",
    "train_y = all_xy[1]\n",
    "test_x = all_xy[2]\n",
    "test_y = all_xy[3]\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507889b2-0430-4c14-afff-912684dcf999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to summaries\n",
    "train_y = ['sostok ' + y + ' eostok' for y in train_y]\n",
    "test_y = ['sostok ' + y + ' eostok' for y in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49af33c4-3084-4a0b-a55c-2109e6319245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.StepPatch at 0x14913fce5400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_lengths = [len(text.split()) for text in train_x]\n",
    "summary_lengths = [len(summary.split()) for summary in train_y]\n",
    "\n",
    "# Show the distribution of text/summary lengths\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "counts_x, bins_x = np.histogram(text_lengths)\n",
    "ax1.stairs(counts_x, bins_x)\n",
    "counts_y, bins_y = np.histogram(summary_lengths)\n",
    "ax2.stairs(counts_y, bins_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7d41be-3d13-44e0-be82-0079824af12c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of texts with < 80 words:  0.9904936014625229\n",
      "Percent of summaries with < 50 words:  0.9912248628884827\n"
     ]
    }
   ],
   "source": [
    "print('Percent of texts with < 80 words: ', len([x for x in train_x if len(x.split()) <= 80]) / len(train_x))\n",
    "print('Percent of summaries with < 50 words: ', len([y for y in train_y if len(y.split()) <= 50]) / len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4f11ec-1cf2-4e33-96c0-5cbd23217d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_text_len = 80\n",
    "max_summary_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354bb460-9414-487d-90a1-d6f013a9ef3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_train_x = []\n",
    "new_train_y = []\n",
    "\n",
    "for i in range(len(train_x)):\n",
    "    if len(train_x[i].split()) <= 80 and len(train_y[i].split()) <= 50:\n",
    "        new_train_x.append(train_x[i])\n",
    "        new_train_y.append(train_y[i])\n",
    "    \n",
    "train_x = np.array(new_train_x)\n",
    "train_y = np.array(new_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac8b338a-4be6-4914-b823-cd19763640a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbb99e2-9595-4b7c-b62f-7dd53679ad8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 16:15:48.981214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-04-19 16:15:48.981241: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-04-19 16:15:48.981261: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0709a-s30.ufhpc): /proc/driver/nvidia/version does not exist\n",
      "2024-04-19 16:15:48.982392: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TextVectorization\n",
    "\n",
    "# Tokenize text and summaries, and pad to maximum length.\n",
    "\n",
    "max_tokens = 5000\n",
    "x_tokenizer = TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='int')\n",
    "x_tokenizer.adapt(train_x)\n",
    "\n",
    "train_x_seq = x_tokenizer(train_x)\n",
    "val_x_seq = x_tokenizer(val_x)\n",
    "test_x_seq = x_tokenizer(test_x)\n",
    "\n",
    "y_tokenizer = TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode='int')\n",
    "y_tokenizer.adapt(train_y)\n",
    "\n",
    "train_y_seq = y_tokenizer(train_y)\n",
    "val_y_seq = y_tokenizer(val_y)\n",
    "test_y_seq = y_tokenizer(test_y)\n",
    "\n",
    "# Pad text/summaries to max length by adding 0s at the end.\n",
    "encoder_input_tr = pad_sequences(train_x_seq, maxlen=max_text_len, padding=\"post\")\n",
    "encoder_input_val = pad_sequences(val_x_seq, maxlen=max_text_len, padding=\"post\")\n",
    "encoder_input_test = pad_sequences(test_x_seq, maxlen=max_text_len, padding=\"post\")\n",
    "\n",
    "decoder_input_tr = pad_sequences(train_y_seq, maxlen=max_summary_len, padding=\"post\")\n",
    "decoder_input_val = pad_sequences(val_y_seq, maxlen=max_summary_len, padding=\"post\")\n",
    "decoder_input_test = pad_sequences(test_y_seq, maxlen=max_summary_len, padding=\"post\")\n",
    "\n",
    "# Move sequence back one step for teacher forcing.\n",
    "decoder_target_tr = np.roll(decoder_input_tr, -1, axis=1)\n",
    "decoder_target_tr[:, -1] = 0 \n",
    "decoder_target_val = np.roll(decoder_input_val, -1, axis=1)\n",
    "decoder_target_val[:, -1] = 0 \n",
    "decoder_target_test = np.roll(decoder_input_test, -1, axis=1)\n",
    "decoder_target_test[:, -1] = 0 \n",
    "\n",
    "x_voc = len(x_tokenizer.get_vocabulary()) + 1\n",
    "y_voc = len(y_tokenizer.get_vocabulary()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab672aab-c2f8-41c1-97c9-da49ec2820ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2151, 80)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b13df28-a111-4e7d-b252-17d0e54314b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_baseline\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " enc_input (InputLayer)         [(None, 80)]         0           []                               \n",
      "                                                                                                  \n",
      " enc_embedding (Embedding)      (None, 80, 80)       113920      ['enc_input[0][0]']              \n",
      "                                                                                                  \n",
      " enc_lstm1 (LSTM)               [(None, 80, 300),    457200      ['enc_embedding[0][0]']          \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " dec_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_lstm2 (LSTM)               [(None, 80, 300),    721200      ['enc_lstm1[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " dec_embedding (Embedding)      (None, None, 200)    204200      ['dec_input[0][0]']              \n",
      "                                                                                                  \n",
      " enc_lstm3 (LSTM)               [(None, 80, 300),    721200      ['enc_lstm2[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " dec_lstm (LSTM)                [(None, None, 300),  601200      ['dec_embedding[0][0]',          \n",
      "                                 (None, 300),                     'enc_lstm3[0][1]',              \n",
      "                                 (None, 300)]                     'enc_lstm3[0][2]']              \n",
      "                                                                                                  \n",
      " dec_output (TimeDistributed)   (None, None, 1021)   307321      ['dec_lstm[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,126,241\n",
      "Trainable params: 3,126,241\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://github.com/karant-dev/Text-summarization-with-Seq2Seq\n",
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder Input\n",
    "encoder_inputs = Input(shape=(max_text_len,), name='enc_input')\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb =  Embedding(x_voc, max_text_len, trainable=True, name='enc_embedding')(encoder_inputs)\n",
    "\n",
    "# Encoder LSTMs\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.5, name='enc_lstm1')\n",
    "encoder_outputs1, state_h1, state_c1= encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.5, name='enc_lstm2')\n",
    "encoder_outputs2, state_h2, state_c2= encoder_lstm2(encoder_outputs1)\n",
    "\n",
    "encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.5, name='enc_lstm3')\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_outputs2)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,), name='dec_input')\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True, name='dec_embedding')\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5, recurrent_dropout=0.25, name='dec_lstm')\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer - softmax\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'), name='dec_output')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='lstm_baseline')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bcd91f-763c-4ccc-955a-bff80c8c2d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_model = 'lstm_model.keras'\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "if os.path.exists(lstm_model):\n",
    "    model = keras.models.load_model(lstm_model)\n",
    "\n",
    "else:\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    early_stop_cb = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    batch_size = 40\n",
    "    epochs = 20\n",
    "\n",
    "    model.fit([encoder_input_tr, decoder_input_tr],\n",
    "              decoder_target_tr,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=([encoder_input_val, decoder_input_val], decoder_target_val),\n",
    "              callbacks=[early_stop_cb]\n",
    "             )\n",
    "\n",
    "    model.save(\"lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b514123-7b22-482b-8a47-c596b7abdbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reverse_encode_seq = dict((index, value) for (index, value) in enumerate(x_tokenizer.get_vocabulary()))\n",
    "reverse_decode_seq = dict((index, value) for (index, value) in enumerate(y_tokenizer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae80ea4-4f88-4319-9336-33b8849340f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference: https://keras.io/examples/nlp/lstm_seq2seq/\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1c970a-0f29-493a-a3b8-320b42855601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_input\n",
      "enc_embedding\n",
      "enc_lstm1\n",
      "dec_input\n",
      "enc_lstm2\n",
      "dec_embedding\n",
      "enc_lstm3\n",
      "dec_lstm\n",
      "dec_output\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the model for inference\n",
    "# Reference: https://keras.io/examples/nlp/lstm_seq2seq/\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "model = keras.models.load_model(\"lstm_model.keras\")\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[6].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_emb = model.layers[5](decoder_inputs)\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[7]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_emb, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[8]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "def decode_sequence(input_sequence, temp=1.0):\n",
    "    states_value = encoder_model.predict(input_sequence, verbose=0)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = y_tokenizer('sostok')\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = sample(output_tokens[0, -1, :], temp)\n",
    "        sampled_vocab = reverse_decode_seq[sampled_token_index]\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if(sampled_vocab != 'eostok' and len(decoded_sentence) < 200):\n",
    "            decoded_sentence += ' ' + sampled_vocab\n",
    "        else:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74835dcc-cfe0-4c1d-be32-6c4eb174a8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate summaries for the test set\n",
    "\n",
    "targets_list = [' '.join(y.split()[1:-1]) for y in test_y]\n",
    "summaries = []\n",
    "\n",
    "for seq_index in range(0, len(encoder_input_test)):\n",
    "    input_seq = encoder_input_test[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq, temp=0.5)\n",
    "    summaries.append(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f510fbe-a4a9-4601-b040-9ecd7ab2eacd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.6994, Recall: 0.6570, F1: 0.6694\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "P, R, F1 = scorer.score(summaries, targets_list)\n",
    "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55bcce2c-ff0f-45e9-988f-93870123ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.0005\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "all_bleu_scores = []\n",
    "for references, candidates in zip(targets_list, summaries):\n",
    "    bleu_score = sentence_bleu([references.split()], candidates.split())\n",
    "    all_bleu_scores.append(bleu_score)\n",
    "\n",
    "average_bleu_score = sum(all_bleu_scores) / len(all_bleu_scores)\n",
    "print(f'Average BLEU Score: {average_bleu_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9e0cc7b-1af4-4f88-aded-93a43e7344e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.44196808016151623\n",
      "Average Precision: 0.526726221624181\n",
      "Average F4: 0.4578809292195143\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "all_rouge_scores = []\n",
    "for references, candidates in zip(targets_list, summaries):\n",
    "    scores = scorer.score(references, candidates)\n",
    "    all_rouge_scores.append(scores[\"rouge1\"])\n",
    "\n",
    "total_recall = sum(score.recall for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "total_precision = sum(score.precision for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "total_fmeasure = sum(score.fmeasure for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "\n",
    "print(f\"Average Recall: {total_recall}\")\n",
    "print(f\"Average Precision: {total_precision}\")\n",
    "print(f\"Average F4: {total_fmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee98f6-c87c-4673-b712-be9f82e807d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
