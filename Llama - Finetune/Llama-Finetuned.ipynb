{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66737e84-ff73-40a1-b8ba-9037d62f3779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "accelerate==0.23.0 bitsandbytes==0.41.1 datasets==2.13.0 openai==0.28.1 \\\n",
    "peft==0.4.0 safetensors==0.4.0 transformers==4.34.0 trl==0.4.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fecba1f-d72e-4bf1-89c2-83c5e254dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "ids = []\n",
    "dialogues = []\n",
    "summaries = []\n",
    "\n",
    "# Open the JSONL file and read its contents line by line\n",
    "with open(\"train.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        # Parse each JSON object in the JSONL file\n",
    "        data = json.loads(line)\n",
    "        # Extract values for 'idx', 'inputs', and 'target'\n",
    "        idx = data[\"idx\"]\n",
    "        dialogue = data[\"inputs\"]\n",
    "        summary = data[\"target\"]\n",
    "        # Append the values to respective lists\n",
    "        ids.append(idx)\n",
    "        dialogues.append(dialogue)\n",
    "        summaries.append(summary)\n",
    "\n",
    "# Create a Hugging Face dataset using the lists of data\n",
    "dataset = Dataset.from_dict({\n",
    "    \"id\": ids,\n",
    "    \"dialogue\": dialogues,\n",
    "    \"summary\": summaries\n",
    "})\n",
    "train_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7faa3b7-5c1e-4185-95ca-684c3ad5d01d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'dialogue': 'The lungs are clear, and without focal air space opacity. The cardiomediastinal silhouette is normal in size and contour, and stable. There is no pneumothorax or large pleural effusion.',\n",
       " 'summary': 'No acute cardiopulmonary abnormality.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de200625-57f4-4a88-ba4f-2ae97e18211e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# \n",
    "# load model in NF4 quantization with double quantization,\n",
    "# set compute dtype to bfloat16\n",
    "# \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    # bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    # use_cache=False,\n",
    "    # device_map=\"auto\",\n",
    ")\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a1fcafc-e1e1-4346-98f5-4d9b9e33a05a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>### Instruction:\n",
      "You are a helpful, respectful and honest assistant. Your task is to summarize the following dialogue. Your answer should be based on the provided dialogue only.\n",
      "\n",
      "### Dialogue:\n",
      "The lungs are clear, and without focal air space opacity. The cardiomediastinal silhouette is normal in size and contour, and stable. There is no pneumothorax or large pleural effusion.\n",
      "\n",
      "### Summary:\n",
      "No acute cardiopulmonary abnormality. </s>\n"
     ]
    }
   ],
   "source": [
    "def prompt_formatter(sample):\n",
    "    return f\"\"\"<s>### Instruction:\n",
    "You are a helpful, respectful and honest assistant. \\\n",
    "Your task is to summarize the following dialogue. \\\n",
    "Your answer should be based on the provided dialogue only.\n",
    "\n",
    "### Dialogue:\n",
    "{sample['dialogue']}\n",
    "\n",
    "### Summary:\n",
    "{sample['summary']} </s>\"\"\"\n",
    "\n",
    "n = 0\n",
    "print(prompt_formatter(train_dataset[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88256810-791e-4024-8d45-6269775747bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_LazyModule' from 'trl.import_utils' (/home/hrudayte.akkalad/.local/lib/python3.8/site-packages/trl/import_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, AutoTokenizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# construct a Peft model.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# the QLoRA paper recommends LoRA dropout = 0.05 for small models (7B, 13B)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      9\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[1;32m     10\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     11\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trl/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.8.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LazyModule, is_diffusers_available, OptionalDependencyNotAvailable\n\u001b[1;32m      8\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     ],\n\u001b[1;32m     61\u001b[0m }\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_LazyModule' from 'trl.import_utils' (/home/hrudayte.akkalad/.local/lib/python3.8/site-packages/trl/import_utils.py)"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# \n",
    "# construct a Peft model.\n",
    "# the QLoRA paper recommends LoRA dropout = 0.05 for small models (7B, 13B)\n",
    "# \n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\", \n",
    ")\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "# \n",
    "# set up the trainer\n",
    "# \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"llama2-7b-chat-opr\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    logging_steps=4,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=prompt_formatter, \n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f11a0265-3205-447d-9f3f-28836053b12a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/hrudayte.akkalad/.local/lib/python3.8/site-packages/~afetensors'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/hrudayte.akkalad/.local/lib/python3.8/site-packages/~~kenizers'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-huggingface 0.1.4 requires huggingface-hub<0.21.0,>=0.20.3, but you have huggingface-hub 0.22.2 which is incompatible.\n",
      "llama-index-llms-huggingface 0.1.4 requires torch<3.0.0,>=2.1.2, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q datasets bitsandbytes einops wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "119f79dd-6c88-4002-8fb5-105d27292a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting lightning-flash[text]\n",
      "  Downloading lightning_flash-0.8.2-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: packaging in /apps/llama/2/lib/python3.8/site-packages (from lightning-flash[text]) (23.2)\n",
      "Requirement already satisfied: setuptools in /apps/llama/2/lib/python3.8/site-packages (from lightning-flash[text]) (68.2.2)\n",
      "Requirement already satisfied: numpy in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (1.24.3)\n",
      "Requirement already satisfied: torch>1.7.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (2.0.1)\n",
      "Collecting torchmetrics<0.11.0,>0.7.0 (from lightning-flash[text])\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pytorch-lightning<2.0.0,>1.8.0 (from lightning-flash[text])\n",
      "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pyDeprecate>0.2.0 (from lightning-flash[text])\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>1.1.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (2.0.3)\n",
      "Collecting jsonargparse>=4.22.0 (from jsonargparse[signatures]>=4.22.0->lightning-flash[text])\n",
      "  Downloading jsonargparse-4.27.7-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (8.1.7)\n",
      "Requirement already satisfied: protobuf in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (4.25.3)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /apps/llama/2/lib/python3.8/site-packages (from fsspec[http]>=2022.5.0->lightning-flash[text]) (2023.12.2)\n",
      "Collecting lightning-utilities>=0.4.1 (from lightning-flash[text])\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: regex in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (2023.12.25)\n",
      "Requirement already satisfied: sentencepiece>=0.1.95 in /apps/llama/2/lib/python3.8/site-packages (from lightning-flash[text]) (0.1.99)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (2.18.0)\n",
      "Requirement already satisfied: filelock in /apps/llama/2/lib/python3.8/site-packages (from lightning-flash[text]) (3.13.1)\n",
      "Requirement already satisfied: sentence-transformers in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (2.5.1)\n",
      "Collecting ftfy (from lightning-flash[text])\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: torchvision in /apps/llama/2/lib/python3.8/site-packages (from lightning-flash[text]) (0.16.1)\n",
      "Requirement already satisfied: transformers>=4.13.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-flash[text]) (4.39.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /apps/llama/2/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /apps/llama/2/lib/python3.8/site-packages (from datasets>=2.0.0->lightning-flash[text]) (6.0.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from jsonargparse[signatures]>=4.22.0->lightning-flash[text]) (0.16)\n",
      "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.22.0->lightning-flash[text])\n",
      "  Downloading typeshed_client-2.5.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from lightning-utilities>=0.4.1->lightning-flash[text]) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /apps/llama/2/lib/python3.8/site-packages (from pandas>1.1.0->lightning-flash[text]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from pandas>1.1.0->lightning-flash[text]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from pandas>1.1.0->lightning-flash[text]) (2024.1)\n",
      "Requirement already satisfied: sympy in /apps/llama/2/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (1.12)\n",
      "Requirement already satisfied: networkx in /apps/llama/2/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/llama/2/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch>1.7.0->lightning-flash[text]) (2.0.0)\n",
      "Requirement already satisfied: wheel in /apps/llama/2/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>1.7.0->lightning-flash[text]) (0.42.0)\n",
      "Requirement already satisfied: cmake in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>1.7.0->lightning-flash[text]) (3.29.2)\n",
      "Requirement already satisfied: lit in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>1.7.0->lightning-flash[text]) (18.1.3)\n",
      "Requirement already satisfied: nltk>=3.6 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torchmetrics[text]>0.5.0; extra == \"text\"->lightning-flash[text]) (3.8.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from transformers>=4.13.0->lightning-flash[text]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from transformers>=4.13.0->lightning-flash[text]) (0.4.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /apps/llama/2/lib/python3.8/site-packages (from ftfy->lightning-flash[text]) (0.2.13)\n",
      "Requirement already satisfied: scikit-learn in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from sentence-transformers->lightning-flash[text]) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from sentence-transformers->lightning-flash[text]) (1.10.1)\n",
      "Requirement already satisfied: Pillow in /apps/llama/2/lib/python3.8/site-packages (from sentence-transformers->lightning-flash[text]) (9.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lightning-flash[text]) (4.0.3)\n",
      "Requirement already satisfied: joblib in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from nltk>=3.6->torchmetrics[text]>0.5.0; extra == \"text\"->lightning-flash[text]) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /apps/llama/2/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>1.1.0->lightning-flash[text]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/llama/2/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->lightning-flash[text]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/llama/2/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->lightning-flash[text]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/llama/2/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->lightning-flash[text]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/llama/2/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=2.0.0->lightning-flash[text]) (2023.11.17)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.22.0->lightning-flash[text]) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/llama/2/lib/python3.8/site-packages (from jinja2->torch>1.7.0->lightning-flash[text]) (2.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers->lightning-flash[text]) (3.4.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /apps/llama/2/lib/python3.8/site-packages (from sympy->torch>1.7.0->lightning-flash[text]) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /apps/llama/2/lib/python3.8/site-packages (from importlib-resources>=1.4.0->typeshed-client>=2.1.0->jsonargparse[signatures]>=4.22.0->lightning-flash[text]) (3.17.0)\n",
      "Downloading jsonargparse-4.27.7-py3-none-any.whl (192 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.2/192.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_flash-0.8.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typeshed_client-2.5.1-py3-none-any.whl (606 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyDeprecate, lightning-utilities, jsonargparse, ftfy, typeshed-client, torchmetrics, pytorch-lightning, lightning-flash\n",
      "Successfully installed ftfy-6.2.0 jsonargparse-4.27.7 lightning-flash-0.8.2 lightning-utilities-0.11.2 pyDeprecate-0.3.2 pytorch-lightning-1.9.5 torchmetrics-0.10.3 typeshed-client-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install 'lightning-flash[text]' --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311debf1-a35e-45b3-b3bc-8e6e591c5be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp38-cp38-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /apps/llama/2/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /apps/llama/2/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /apps/llama/2/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/llama/2/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /apps/llama/2/lib/python3.8/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hrudayte.akkalad/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/llama/2/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /apps/llama/2/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.2-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Installing collected packages: triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/hrudayte.akkalad/.local/lib/python3.8/site-packages/~-iton'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338aaba8-b04a-4d65-bd0b-f814caa281fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLAMA2",
   "language": "python",
   "name": "llama2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
