{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ede4db59-1b6b-4192-a121-cd94e04393e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForPreTraining\n",
    "from nltk.tokenize import sent_tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a278bdd-30f1-4529-bb59-d33f07f3ade2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "256d38dc-31ec-499c-b464-7ff105a97f07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reference for fine tuning BERT: https://towardsdatascience.com/how-to-train-bert-aaad00533168\n",
    "import json\n",
    "file_paths = ['data/chq/train.jsonl', 'data/opi/train.jsonl', 'data/d2n/train.jsonl']\n",
    "\n",
    "inputs_list = []\n",
    "targets_list = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            if file_path == \"data/d2n/train.jsonl\":\n",
    "                preprocessed = data['inputs'].replace('[', '.')\n",
    "                preprocessed = preprocessed.replace(']', ':')\n",
    "                inputs_list.append(preprocessed)\n",
    "            else:\n",
    "                inputs_list.append(data['inputs'])\n",
    "            targets_list.append(data['target'])\n",
    "        \n",
    "bag = [item for sentence in inputs_list for item in sentence.split('.') if item != '']\n",
    "bag_size = len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46f77d48-abe0-4de5-a409-fc2fd7e396aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in inputs_list:\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph.split('.') if sentence != ''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        if random.random() >= 0.5:\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(bag[index])\n",
    "            label.append(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d2d8aa-a75e-4bd0-b76d-a038aca97d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt',\n",
    "                   max_length=512, truncation=True, padding='max_length')\n",
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c88be7c-599f-4bff-b15b-cc3e5bcb1568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "\n",
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d4d7b8a-1eae-4015-a51a-3f90cb39776b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "dataset = BERTDataset(inputs)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "130ceea8-153f-4154-a6f5-577cb217a472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]/scratch/local/28553553/ipykernel_1228125/284286799.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.69] \n",
      "Epoch 1: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.432]\n",
      "Epoch 2: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.277]\n",
      "Epoch 3: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.224]\n",
      "Epoch 4: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.216]\n",
      "Epoch 5: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.113] \n",
      "Epoch 6: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.043] \n",
      "Epoch 7: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.0629]\n",
      "Epoch 8: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.0381]\n",
      "Epoch 9: 100%|██████████| 37/37 [01:25<00:00,  2.30s/it, loss=0.0256]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 10\n",
    "model.cuda()\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d888e16-3347-4a22-9c19-9e65c24d0552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "111e9cfe-5b11-4237-9d26-d740816691ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "650f7b35-155a-4fbd-a035-f460427eb686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jordan.sabo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#reference for using BERT for summarization: https://blog.devgenius.io/bert-for-text-summarization-in-python-4c527179cd98\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "model1.cuda()\n",
    "\n",
    "file_paths = ['data/chq/test.jsonl', 'data/opi/test.jsonl', 'data/d2n/test.jsonl']\n",
    "\n",
    "inputs_list = []\n",
    "targets_list = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            if file_path == \"data/d2n/train.jsonl\":\n",
    "                preprocessed = data['inputs'].replace('[', '.')\n",
    "                preprocessed = preprocessed.replace(']', ':')\n",
    "                inputs_list.append(preprocessed)\n",
    "            else:\n",
    "                inputs_list.append(data['inputs'])\n",
    "            targets_list.append(data['target'])\n",
    "\n",
    "num = 0\n",
    "summaries = []\n",
    "for input in inputs_list:\n",
    "    sentences = sent_tokenize(input)\n",
    "    tokenized_sentences = [tokenizer.encode(sent, add_special_tokens=True, truncation=True, max_length=512) for sent in sentences]\n",
    "    max_len = 0\n",
    "    for i in tokenized_sentences:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded_sentences = []\n",
    "    for i in tokenized_sentences:\n",
    "        while len(i) < max_len:\n",
    "            i.append(0)\n",
    "        padded_sentences.append(i)\n",
    "\n",
    "    input_ids = torch.tensor(padded_sentences).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model1(input_ids)[0]\n",
    "\n",
    "    sentence_embeddings = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence_embeddings.append(torch.mean(last_hidden_states[i], dim=0).cpu().numpy())\n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "\n",
    "    num_sentences = 2\n",
    "    summary_sentences = []\n",
    "    for i in range(min(num_sentences, len(sentences))):\n",
    "        sentence_scores = list(enumerate(similarity_matrix[i]))\n",
    "        sentence_scores = sorted(sentence_scores, key=lambda x: x[1], reverse=True)\n",
    "        if len(sentences) == 1:\n",
    "            summary_sentences.append(sentences[0])\n",
    "        else:\n",
    "            summary_sentences.append(sentences[sentence_scores[1][0]])\n",
    "\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    summaries.append(summary)\n",
    "    num = num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d1767dd-fb81-4890-919d-1e46efa0c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.6953, Recall: 0.8946, F1: 0.7751\n"
     ]
    }
   ],
   "source": [
    "from bert_score import BERTScorer\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "P, R, F1 = scorer.score(inputs_list, summaries)\n",
    "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e9db74c-463f-40cb-a154-2bae5650b17f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.3599\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "all_bleu_scores = []\n",
    "for references, candidates in zip(inputs_list, summaries):\n",
    "    bleu_score = sentence_bleu([references.split()], candidates.split())\n",
    "    all_bleu_scores.append(bleu_score)\n",
    "\n",
    "average_bleu_score = sum(all_bleu_scores) / len(all_bleu_scores)\n",
    "print(f'Average BLEU Score: {average_bleu_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d4681f0-62a9-42c9-97bb-6550a1e869d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.4883396562691781\n",
      "Average Precision: 0.9600702228898178\n",
      "Average F4: 0.591478932954273\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "\n",
    "all_rouge_scores = []\n",
    "for references, candidates in zip(inputs_list, summaries):\n",
    "    scores = scorer.score(references, candidates)\n",
    "    all_rouge_scores.append(scores[\"rouge1\"])\n",
    "\n",
    "total_recall = sum(score.recall for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "total_precision = sum(score.precision for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "total_fmeasure = sum(score.fmeasure for score in all_rouge_scores) / len(all_rouge_scores)\n",
    "\n",
    "print(f\"Average Recall: {total_recall}\")\n",
    "print(f\"Average Precision: {total_precision}\")\n",
    "print(f\"Average F4: {total_fmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42c36f-ac54-43d0-9c37-0ef6581929ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
